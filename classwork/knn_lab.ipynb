{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use the question/target variable you submitted and build a model to answer the question you created for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grad_data = pd.read_csv('https://query.data.world/s/qpi2ltkz23yp2fcaz4jmlrskjx5qnp', encoding=\"cp1252\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Using the different statistics from different colleges, can we predict their retention percentile (whether it is over or under 70%)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = list(range(38, 56))\n",
    "to_drop.extend([27, 9, 10, 11, 28, 60, 56])\n",
    "\n",
    "grad_data1 = grad_data.drop(grad_data.columns[to_drop], axis=1)\n",
    "\n",
    "drop_more = [0,1,2,3,6,8,11,12,14,15,18,21,23,29,32,33,34,35]\n",
    "grad_data2 = grad_data1.drop(grad_data1.columns[drop_more], axis=1)\n",
    "grad_data2.replace('NULL', np.nan, inplace=True)\n",
    "\n",
    "grad_data2['hbcu'] = [1 if grad_data2['hbcu'][i]=='X' else 0 for i in range(len(grad_data2['hbcu']))]\n",
    "grad_data2['hbcu'].value_counts()\n",
    "\n",
    "grad_data2['hbcu'] = grad_data2.hbcu.astype('category')\n",
    "    # convert more variables to factors\n",
    "grad_data2[['level', 'control']] = grad_data2[['level', 'control']].astype('category')\n",
    "grad_data2['retain_percentile'] = grad_data1['retain_percentile'].apply(lambda x: 1 if x >= 70 else 0)\n",
    "\n",
    "abc = list(grad_data2.select_dtypes('number')) #select function to find the numeric variables and create a list  \n",
    "grad_data2[abc] = MinMaxScaler().fit_transform(grad_data2[abc])\n",
    "random.seed(1234)\n",
    "category_list = list(grad_data2.select_dtypes('category'))\n",
    "grad_data2 = pd.get_dummies(grad_data2, columns = category_list)\n",
    "grad_data2 = grad_data2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "def retention_class(x):\n",
    "    Train, Test = train_test_split(grad_data2,  train_size = 55, stratify = grad_data2.retain_percentile, random_state=42) \n",
    "    Tune, Test = train_test_split(Test,  train_size = .5, stratify= Test.retain_percentile)\n",
    "    dtree = DecisionTreeClassifier()\n",
    "\n",
    "    # separate features and target variable\n",
    "    X_train = Train.drop('retain_percentile', axis=1)\n",
    "    y_train = Train['retain_percentile']\n",
    "    X_test = Test.drop('retain_percentile', axis=1)\n",
    "    y_test = Test['retain_percentile']\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    dtree.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    y_pred_dtree = dtree.predict(X_test)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, y_pred_dtree)\n",
    "    print(precision)\n",
    "     \n",
    "retention_class(grad_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a kNN model to predict your target variable using 3 nearest neighbors. Make sure it is a classification problem, meaning if needed changed the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "grad_data3 = pd.get_dummies(grad_data2, columns=['retain_percentile'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train, test = train_test_split(grad_data3, test_size=0.4, stratify=grad_data3['retain_percentile_1.0'], random_state=12345) \n",
    "test, val = train_test_split(test, test_size=0.5, stratify=test['retain_percentile_1.0'], random_state=12345)\n",
    "\n",
    "#! make sure you also drop signed up 0, so that the model isn't just memorizing\n",
    "\n",
    "\n",
    "X_train = train.drop(['retain_percentile_0.0', 'retain_percentile_1.0'], axis=1).values\n",
    "y_train = train['retain_percentile_1.0'].values\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "X_val = val.drop(['retain_percentile_0.0', 'retain_percentile_1.0'], axis=1).values\n",
    "y_val = val['retain_percentile_1.0'].values\n",
    "\n",
    "y_val_pred = neigh.predict(X_val)\n",
    "\n",
    "print(neigh.score(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a dataframe that includes the test target values, test predicted values, and test probabilities of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Actual",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Predicted",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "Probability_Positive_Class",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9b41fbc6-7717-481b-864a-ffa8892ed94a",
       "rows": [
        [
         "0",
         "False",
         "False",
         "0.0"
        ],
        [
         "1",
         "False",
         "True",
         "0.6666666666666666"
        ],
        [
         "2",
         "False",
         "False",
         "0.0"
        ],
        [
         "3",
         "False",
         "False",
         "0.0"
        ],
        [
         "4",
         "True",
         "False",
         "0.0"
        ],
        [
         "5",
         "False",
         "False",
         "0.0"
        ],
        [
         "6",
         "False",
         "False",
         "0.0"
        ],
        [
         "7",
         "True",
         "False",
         "0.3333333333333333"
        ],
        [
         "8",
         "False",
         "False",
         "0.0"
        ],
        [
         "9",
         "False",
         "False",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Probability_Positive_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted  Probability_Positive_Class\n",
       "0   False      False                    0.000000\n",
       "1   False       True                    0.666667\n",
       "2   False      False                    0.000000\n",
       "3   False      False                    0.000000\n",
       "4    True      False                    0.000000\n",
       "5   False      False                    0.000000\n",
       "6   False      False                    0.000000\n",
       "7    True      False                    0.333333\n",
       "8   False      False                    0.000000\n",
       "9   False      False                    0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_pred = neigh.predict(X_val)\n",
    "y_prob = neigh.predict_proba(X_val)[:, 1] \n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_val,\n",
    "    'Predicted': y_pred,\n",
    "    'Probability_Positive_Class': y_prob\n",
    "})\n",
    "\n",
    "# Display the first few rows\n",
    "results_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. No code question: If you adjusted the k hyperparameter what do you think would happen to the threshold function? Would the confusion look the same at the same threshold levels or not? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K hyperparameter that we choose has a large effect on the threshold function. If the k value is lower, then fewer points are taken into consideration, meaning that the threshold function results will be more extreme to certain ends (like seeing 0.1 or 0.9). Our threshold function takes those results from the model and then determines whether it will be classified as one thing or the other. Therefore lowering the k hyperparameter would make the threshold function more sharp and split, while raising the k hyperparameter would make the threshold less sharp and decisive. \n",
    "\n",
    "The confusion matrix would not look the same at the same threshold levels because as the k changes, the confusion matrix would show that the model is making sharper decisions as k goes down, and softer decisions as k goes up. The confusions matrix would change as this k value is changing, as the predictions the model is spitting out would differ, and therefore certain things would be placed above or below the threshold differently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the results using the confusion matrix. Then \"walk\" through your question, summarize what concerns or positive elements do you have about the model as it relates to your question? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val,y_val_pred, labels=neigh.classes_)\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=neigh.classes_)  \n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our confusion matrix, we can see that there were 159 true negatives, 65 true positives, 17 false positives and 23 false negatives. Our question was whether we can use the features in the dataset to predict whether a school will be in a retention percentile over 70%. We can see that the model on average was able to identify 159 true negatives effectively, while only classifying 23 false negatives. The model was able to classify 65 true positives, however there were also 17 false positives, which is a large percentage of the predictions. This makes sense, because we are trying to classify the data based on whether it is above or below the 70% percentile mark, meaning that there will be more data points below that mark and therefore the model has a better chance of making that correct prediction. One concern of mine is that the precision score isn't accurate enough for this model to be effectively used in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create two functions: One that cleans the data & splits into training|test and one that allows you to train and test the model with different k and threshold values, then use them to optimize your model (test your model with several k and threshold combinations). Try not to use variable names in the functions, but if you need to that's fine. (If you can't get the k function and threshold function to work in one function just run them separately.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_split_data(df, target, test_size=0.4, val_size=0.5, random_state=2004):\n",
    "    train, test = train_test_split(grad_data3, test_size=0.4, stratify=df[target], random_state=12345) \n",
    "    test, val = train_test_split(test, test_size=0.5, stratify=test[target], random_state=12345)\n",
    "\n",
    "    \n",
    "    X_train = train.drop([target], axis=1).values\n",
    "    y_train = train[target].values\n",
    "    X_val = val.drop([target], axis=1).values\n",
    "    y_val = val[target].values\n",
    "    \n",
    "    return train, test, val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(X_train, y_train, X_val, y_val, k=3, threshold=0.5):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = neigh.predict(X_val)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseK(k, X_train, y_train, X_test, y_test):\n",
    "    random.seed(1)\n",
    "    print(\"calculating... \", k, \"k\")    # I'll include this so you can see the progress of the function as it runs\n",
    "    class_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    class_knn.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    accu = class_knn.score(X_test, y_test)\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. How well does the model perform? Did the interaction of the adjusted thresholds and k values help the model? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      student_count  awards_per_value  exp_award_value  exp_award_percentile  \\\n",
       " 1619       0.031154          0.169220         0.072598                  0.99   \n",
       " 2034       0.006055          0.167031         0.012211                  0.36   \n",
       " 1267       0.009764          0.129832         0.020265                  0.73   \n",
       " 2375       0.004838          0.172137         0.000000                  0.00   \n",
       " 1160       0.011045          0.154632         0.017680                  0.63   \n",
       " ...             ...               ...              ...                   ...   \n",
       " 3016       0.178832          0.167031         0.017532                  0.86   \n",
       " 1403       0.015371          0.156090         0.011141                  0.52   \n",
       " 506        0.001640          0.107950         0.016575                  0.58   \n",
       " 634        0.154331          0.195478         0.010362                  0.44   \n",
       " 2957       0.016923          0.125456         0.017101                  0.60   \n",
       " \n",
       "         ft_pct  fte_percentile  med_sat_value  aid_value  grad_100_value  \\\n",
       " 1619  0.984407            0.93       0.955069   0.892942           0.878   \n",
       " 2034  0.787942            0.34       0.415899   0.585695           0.524   \n",
       " 1267  0.941788            0.57       0.612903   0.350119           0.114   \n",
       " 2375  0.762994            0.03       0.315668   0.121591           0.206   \n",
       " 1160  0.752599            0.55       0.391705   0.318801           0.161   \n",
       " ...        ...             ...            ...        ...             ...   \n",
       " 3016  0.938669            0.97       0.627880   0.210701           0.418   \n",
       " 1403  0.813929            0.19       0.327189   0.130674           0.164   \n",
       " 506   0.758836            0.15       0.350230   0.111297           0.065   \n",
       " 634   0.939709            0.94       0.669355   0.179044           0.568   \n",
       " 2957  0.884615            0.83       0.505760   0.487792           0.543   \n",
       " \n",
       "       grad_100_percentile  ...  cohort_size  level_2-year  level_4-year  \\\n",
       " 1619                 0.98  ...     0.076534         False          True   \n",
       " 2034                 0.66  ...     0.012632         False          True   \n",
       " 1267                 0.05  ...     0.023663         False          True   \n",
       " 2375                 0.45  ...     0.009798         False          True   \n",
       " 1160                 0.09  ...     0.019411         False          True   \n",
       " ...                   ...  ...          ...           ...           ...   \n",
       " 3016                 0.84  ...     0.398386         False          True   \n",
       " 1403                 0.33  ...     0.029332         False          True   \n",
       " 506                  0.03  ...     0.001849         False          True   \n",
       " 634                  0.93  ...     0.288021         False          True   \n",
       " 2957                 0.69  ...     0.042026         False          True   \n",
       " \n",
       "       control_Private for-profit  control_Private not-for-profit  \\\n",
       " 1619                       False                            True   \n",
       " 2034                       False                            True   \n",
       " 1267                       False                            True   \n",
       " 2375                       False                           False   \n",
       " 1160                       False                            True   \n",
       " ...                          ...                             ...   \n",
       " 3016                       False                           False   \n",
       " 1403                       False                           False   \n",
       " 506                        False                            True   \n",
       " 634                        False                           False   \n",
       " 2957                       False                            True   \n",
       " \n",
       "       control_Public  hbcu_0  hbcu_1  retain_percentile_0.0  \\\n",
       " 1619           False    True   False                  False   \n",
       " 2034           False    True   False                   True   \n",
       " 1267           False    True   False                  False   \n",
       " 2375            True    True   False                   True   \n",
       " 1160           False    True   False                   True   \n",
       " ...              ...     ...     ...                    ...   \n",
       " 3016            True    True   False                  False   \n",
       " 1403            True    True   False                   True   \n",
       " 506            False    True   False                   True   \n",
       " 634             True    True   False                  False   \n",
       " 2957           False    True   False                   True   \n",
       " \n",
       "       retain_percentile_1.0  \n",
       " 1619                   True  \n",
       " 2034                  False  \n",
       " 1267                   True  \n",
       " 2375                  False  \n",
       " 1160                  False  \n",
       " ...                     ...  \n",
       " 3016                   True  \n",
       " 1403                  False  \n",
       " 506                   False  \n",
       " 634                    True  \n",
       " 2957                  False  \n",
       " \n",
       " [791 rows x 24 columns],\n",
       "       student_count  awards_per_value  exp_award_value  exp_award_percentile  \\\n",
       " 755        0.026981          0.176513         0.010208                  0.25   \n",
       " 1349       0.011850          0.166302         0.030638                  0.88   \n",
       " 476        0.031783          0.133479         0.105389                  1.00   \n",
       " 120        0.025893          0.140773         0.013310                  0.42   \n",
       " 2773       0.016900          0.150255         0.014448                  0.48   \n",
       " ...             ...               ...              ...                   ...   \n",
       " 1333       0.014742          0.155361         0.018526                  0.67   \n",
       " 2366       0.003427          0.087527         0.000000                  0.00   \n",
       " 2725       0.150875          0.186725         0.006537                  0.11   \n",
       " 2245       0.134634          0.170678         0.007939                  0.17   \n",
       " 903        0.003386          0.191101         0.014719                  0.50   \n",
       " \n",
       "         ft_pct  fte_percentile  med_sat_value  aid_value  grad_100_value  \\\n",
       " 755   0.799376            0.90       0.486175   0.286950           0.448   \n",
       " 1349  0.985447            0.67       0.788018   0.716151           0.847   \n",
       " 476   0.998960            0.96       0.957373   0.988010           0.896   \n",
       " 120   0.924116            0.90       0.544931   0.215424           0.404   \n",
       " 2773  0.797297            0.73       0.525346   0.246839           0.500   \n",
       " ...        ...             ...            ...        ...             ...   \n",
       " 1333  0.982328            0.80       0.550691   0.414959           0.617   \n",
       " 2366  0.850312            0.01       0.379032   0.114446           0.302   \n",
       " 2725  0.604990            0.92       0.473502   0.145497           0.169   \n",
       " 2245  0.625780            0.83       0.436636   0.136947           0.177   \n",
       " 903   0.797297            0.22       0.390553   0.534636           0.173   \n",
       " \n",
       "       grad_100_percentile  ...  cohort_size  level_2-year  level_4-year  \\\n",
       " 755                  0.54  ...     0.038883         False          True   \n",
       " 1349                 0.96  ...     0.029825         False          True   \n",
       " 476                  0.99  ...     0.080848         False          True   \n",
       " 120                  0.46  ...     0.059095         False          True   \n",
       " 2773                 0.62  ...     0.027915         False          True   \n",
       " ...                   ...  ...          ...           ...           ...   \n",
       " 1333                 0.79  ...     0.050961         False          True   \n",
       " 2366                 0.69  ...     0.009736         False          True   \n",
       " 2725                 0.35  ...     0.129098         False          True   \n",
       " 2245                 0.37  ...     0.087873         False          True   \n",
       " 903                  0.10  ...     0.007764         False          True   \n",
       " \n",
       "       control_Private for-profit  control_Private not-for-profit  \\\n",
       " 755                        False                            True   \n",
       " 1349                       False                            True   \n",
       " 476                        False                            True   \n",
       " 120                        False                            True   \n",
       " 2773                       False                            True   \n",
       " ...                          ...                             ...   \n",
       " 1333                       False                            True   \n",
       " 2366                       False                           False   \n",
       " 2725                       False                           False   \n",
       " 2245                       False                           False   \n",
       " 903                        False                            True   \n",
       " \n",
       "       control_Public  hbcu_0  hbcu_1  retain_percentile_0.0  \\\n",
       " 755            False    True   False                   True   \n",
       " 1349           False    True   False                  False   \n",
       " 476            False    True   False                  False   \n",
       " 120            False    True   False                  False   \n",
       " 2773           False    True   False                   True   \n",
       " ...              ...     ...     ...                    ...   \n",
       " 1333           False    True   False                  False   \n",
       " 2366            True    True   False                  False   \n",
       " 2725            True    True   False                   True   \n",
       " 2245            True    True   False                   True   \n",
       " 903            False    True   False                   True   \n",
       " \n",
       "       retain_percentile_1.0  \n",
       " 755                   False  \n",
       " 1349                   True  \n",
       " 476                    True  \n",
       " 120                    True  \n",
       " 2773                  False  \n",
       " ...                     ...  \n",
       " 1333                   True  \n",
       " 2366                   True  \n",
       " 2725                  False  \n",
       " 2245                  False  \n",
       " 903                   False  \n",
       " \n",
       " [264 rows x 24 columns],\n",
       "       student_count  awards_per_value  exp_award_value  exp_award_percentile  \\\n",
       " 2974       0.005308          0.180160         0.010277                  0.26   \n",
       " 2714       0.182117          0.154632         0.008004                  0.17   \n",
       " 50         0.004938          0.082422         0.024285                  0.82   \n",
       " 840        0.060222          0.115974         0.012585                  0.64   \n",
       " 370        0.001258          0.142961         0.023418                  0.80   \n",
       " ...             ...               ...              ...                   ...   \n",
       " 2579       0.011780          0.140044         0.030949                  0.89   \n",
       " 2119       0.015748          0.135667         0.019365                  0.70   \n",
       " 311        0.009534          0.155361         0.015708                  0.54   \n",
       " 819        0.095679          0.142232         0.012323                  0.63   \n",
       " 831        0.002945          0.113786         0.022420                  0.78   \n",
       " \n",
       "         ft_pct  fte_percentile  med_sat_value  aid_value  grad_100_value  \\\n",
       " 2974  0.729730            0.30       0.335253   0.308192           0.210   \n",
       " 2714  0.821206            0.95       0.436636   0.137310           0.304   \n",
       " 50    0.933472            0.34       0.248848   0.175168           0.169   \n",
       " 840   0.884615            0.65       0.281106   0.172528           0.222   \n",
       " 370   0.956341            0.10       0.542627   0.282008           0.000   \n",
       " ...        ...             ...            ...        ...             ...   \n",
       " 2579  0.993763            0.66       0.716590   0.522550           0.741   \n",
       " 2119  0.804574            0.75       0.561060   0.786780           0.531   \n",
       " 311   0.879418            0.52       0.404378   0.317807           0.236   \n",
       " 819   0.925156            0.81       0.445853   0.199438           0.351   \n",
       " 831   0.944906            0.17       0.400922   0.498692           0.420   \n",
       " \n",
       "       grad_100_percentile  ...  cohort_size  level_2-year  level_4-year  \\\n",
       " 2974                 0.15  ...     0.007271         False          True   \n",
       " 2714                 0.70  ...     0.199408         False          True   \n",
       " 50                   0.10  ...     0.023231         False          True   \n",
       " 840                  0.51  ...     0.103895         False          True   \n",
       " 370                  0.00  ...     0.003143         False          True   \n",
       " ...                   ...  ...          ...           ...           ...   \n",
       " 2579                 0.89  ...     0.027791         False          True   \n",
       " 2119                 0.67  ...     0.034385         False          True   \n",
       " 311                  0.18  ...     0.013803         False          True   \n",
       " 819                  0.76  ...     0.214506         False          True   \n",
       " 831                  0.49  ...     0.010784         False          True   \n",
       " \n",
       "       control_Private for-profit  control_Private not-for-profit  \\\n",
       " 2974                       False                            True   \n",
       " 2714                       False                           False   \n",
       " 50                         False                            True   \n",
       " 840                        False                           False   \n",
       " 370                        False                            True   \n",
       " ...                          ...                             ...   \n",
       " 2579                       False                            True   \n",
       " 2119                       False                            True   \n",
       " 311                        False                            True   \n",
       " 819                        False                           False   \n",
       " 831                        False                            True   \n",
       " \n",
       "       control_Public  hbcu_0  hbcu_1  retain_percentile_0.0  \\\n",
       " 2974           False    True   False                   True   \n",
       " 2714            True    True   False                   True   \n",
       " 50             False   False    True                   True   \n",
       " 840             True    True   False                   True   \n",
       " 370            False    True   False                  False   \n",
       " ...              ...     ...     ...                    ...   \n",
       " 2579           False    True   False                  False   \n",
       " 2119           False    True   False                  False   \n",
       " 311            False    True   False                  False   \n",
       " 819             True    True   False                   True   \n",
       " 831            False    True   False                   True   \n",
       " \n",
       "       retain_percentile_1.0  \n",
       " 2974                  False  \n",
       " 2714                  False  \n",
       " 50                    False  \n",
       " 840                   False  \n",
       " 370                    True  \n",
       " ...                     ...  \n",
       " 2579                   True  \n",
       " 2119                   True  \n",
       " 311                    True  \n",
       " 819                   False  \n",
       " 831                   False  \n",
       " \n",
       " [264 rows x 24 columns])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_split_data(grad_data3,'retain_percentile_1.0', test_size=0.4, val_size=0.5, random_state=2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating...  5 k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chooseK(5, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162,  14],\n",
       "       [ 19,  69]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_test(X_train, y_train, X_val, y_val, k=5, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, my model was improved by doing this. I used the chooseK function given to us in class and was able to find the best k value that led to the most accurate knn model. The k value started off being 3, and this was a relatively low number, meaning that the model may have been overfitting. I then raised it to 5 (after that the accuracy starts to taper off), and the accuracy went up, meaning the model was better able to find the overall relationship between the variables. The model was able to raise the number of true negatives to 162, and the number of true positives to 69, with an overall accuracy of around 88%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Choose another variable as the target in the dataset and create another kNN model using the two functions you created in step 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      student_count  awards_per_value  exp_award_value  exp_award_percentile  \\\n",
       " 1531       0.002275          0.204230         0.009745                  0.22   \n",
       " 2349       0.016159          0.154632         0.019225                  0.69   \n",
       " 446        0.057300          0.148796         0.012136                  0.61   \n",
       " 2105       0.010416          0.168490         0.010131                  0.25   \n",
       " 824        0.013408          0.161196         0.026851                  0.85   \n",
       " ...             ...               ...              ...                   ...   \n",
       " 683        0.000958          0.135667         0.006854                  0.09   \n",
       " 1619       0.031154          0.169220         0.072598                  0.99   \n",
       " 2665       0.055014          0.117433         0.007000                  0.13   \n",
       " 399        0.153262          0.161196         0.014757                  0.77   \n",
       " 2062       0.005108          0.151714         0.016064                  0.56   \n",
       " \n",
       "         ft_pct  fte_percentile  med_sat_value  aid_value  grad_100_value  \\\n",
       " 1531  0.825364            0.13       0.379032   0.350385           0.232   \n",
       " 2349  0.972973            0.81       0.562212   0.353825           0.711   \n",
       " 446   0.771310            0.60       0.391705   0.113259           0.201   \n",
       " 2105  0.668399            0.54       0.372120   0.298576           0.385   \n",
       " 824   0.989605            0.73       0.632488   0.574892           0.742   \n",
       " ...        ...             ...            ...        ...             ...   \n",
       " 683   0.893971            0.06       0.358295   0.147895           0.231   \n",
       " 1619  0.984407            0.93       0.955069   0.892942           0.878   \n",
       " 2665  0.692308            0.62       0.354839   0.118176           0.131   \n",
       " 399   0.914761            0.94       0.605991   0.219227           0.443   \n",
       " 2062  0.813929            0.32       0.343318   0.343724           0.376   \n",
       " \n",
       "       grad_100_percentile  ...  cohort_size  level_2-year  level_4-year  \\\n",
       " 1531                 0.17  ...     0.004991         False          True   \n",
       " 2349                 0.87  ...     0.044491         False          True   \n",
       " 446                  0.43  ...     0.090276         False          True   \n",
       " 2105                 0.43  ...     0.020582         False          True   \n",
       " 824                  0.89  ...     0.040855         False          True   \n",
       " ...                   ...  ...          ...           ...           ...   \n",
       " 683                  0.17  ...     0.001541         False          True   \n",
       " 1619                 0.98  ...     0.076534         False          True   \n",
       " 2665                 0.22  ...     0.087195         False          True   \n",
       " 399                  0.87  ...     0.341324         False          True   \n",
       " 2062                 0.42  ...     0.013865         False          True   \n",
       " \n",
       "       control_Private for-profit  control_Private not-for-profit  \\\n",
       " 1531                       False                            True   \n",
       " 2349                       False                            True   \n",
       " 446                        False                           False   \n",
       " 2105                       False                            True   \n",
       " 824                        False                            True   \n",
       " ...                          ...                             ...   \n",
       " 683                        False                            True   \n",
       " 1619                       False                            True   \n",
       " 2665                       False                           False   \n",
       " 399                        False                           False   \n",
       " 2062                       False                            True   \n",
       " \n",
       "       control_Public  hbcu_0  hbcu_1  retain_percentile_0.0  \\\n",
       " 1531           False    True   False                   True   \n",
       " 2349           False    True   False                  False   \n",
       " 446             True    True   False                   True   \n",
       " 2105           False    True   False                   True   \n",
       " 824            False    True   False                  False   \n",
       " ...              ...     ...     ...                    ...   \n",
       " 683            False    True   False                   True   \n",
       " 1619           False    True   False                  False   \n",
       " 2665            True    True   False                   True   \n",
       " 399             True    True   False                  False   \n",
       " 2062           False    True   False                   True   \n",
       " \n",
       "       retain_percentile_1.0  \n",
       " 1531                  False  \n",
       " 2349                   True  \n",
       " 446                   False  \n",
       " 2105                  False  \n",
       " 824                    True  \n",
       " ...                     ...  \n",
       " 683                   False  \n",
       " 1619                   True  \n",
       " 2665                  False  \n",
       " 399                    True  \n",
       " 2062                  False  \n",
       " \n",
       " [791 rows x 24 columns],\n",
       "       student_count  awards_per_value  exp_award_value  exp_award_percentile  \\\n",
       " 893        0.012185          0.170678         0.010889                  0.29   \n",
       " 2897       0.014819          0.173596         0.022414                  0.78   \n",
       " 830        0.006701          0.138585         0.025083                  0.84   \n",
       " 1733       0.004332          0.132020         0.010601                  0.65   \n",
       " 1183       0.024818          0.150985         0.009972                  0.38   \n",
       " ...             ...               ...              ...                   ...   \n",
       " 1940       0.008629          0.132020         0.013843                  0.46   \n",
       " 1530       0.006407          0.132020         0.019541                  0.70   \n",
       " 191        0.006007          0.103574         0.034793                  0.99   \n",
       " 471        0.048401          0.158279         0.011756                  0.57   \n",
       " 2912       0.135474          0.178702         0.012221                  0.62   \n",
       " \n",
       "         ft_pct  fte_percentile  med_sat_value  aid_value  grad_100_value  \\\n",
       " 893   0.817048            0.65       0.360599   0.232912           0.281   \n",
       " 2897  0.990644            0.75       0.653226   0.490190           0.682   \n",
       " 830   0.995842            0.41       0.534562   0.497626           0.684   \n",
       " 1733  0.948025            0.66       0.262673   0.179528           0.300   \n",
       " 1183  0.802495            0.31       0.369816   0.118781           0.203   \n",
       " ...        ...             ...            ...        ...             ...   \n",
       " 1940  0.871102            0.53       0.357143   0.452672           0.398   \n",
       " 1530  0.993763            0.41       0.473502   0.332413           0.510   \n",
       " 191   0.963617            0.07       0.476959   0.211089           0.426   \n",
       " 471   0.844075            0.54       0.293779   0.136996           0.179   \n",
       " 2912  0.875260            0.90       0.419355   0.230248           0.400   \n",
       " \n",
       "       grad_100_percentile  ...  cohort_size  level_2-year  level_4-year  \\\n",
       " 893                  0.25  ...     0.010476         False          True   \n",
       " 2897                 0.85  ...     0.039438         False          True   \n",
       " 830                  0.85  ...     0.014173         False          True   \n",
       " 1733                 0.71  ...     0.007333         False          True   \n",
       " 1183                 0.44  ...     0.042950         False          True   \n",
       " ...                   ...  ...          ...           ...           ...   \n",
       " 1940                 0.45  ...     0.022554         False          True   \n",
       " 1530                 0.64  ...     0.015898         False          True   \n",
       " 191                  0.85  ...     0.009490         False          True   \n",
       " 471                  0.38  ...     0.082080         False          True   \n",
       " 2912                 0.82  ...     0.196142         False          True   \n",
       " \n",
       "       control_Private for-profit  control_Private not-for-profit  \\\n",
       " 893                        False                            True   \n",
       " 2897                       False                            True   \n",
       " 830                        False                            True   \n",
       " 1733                        True                           False   \n",
       " 1183                       False                           False   \n",
       " ...                          ...                             ...   \n",
       " 1940                       False                            True   \n",
       " 1530                       False                            True   \n",
       " 191                        False                           False   \n",
       " 471                        False                           False   \n",
       " 2912                       False                           False   \n",
       " \n",
       "       control_Public  hbcu_0  hbcu_1  retain_percentile_0.0  \\\n",
       " 893            False    True   False                   True   \n",
       " 2897           False    True   False                  False   \n",
       " 830            False    True   False                   True   \n",
       " 1733           False    True   False                   True   \n",
       " 1183            True    True   False                   True   \n",
       " ...              ...     ...     ...                    ...   \n",
       " 1940           False    True   False                   True   \n",
       " 1530           False    True   False                   True   \n",
       " 191             True    True   False                  False   \n",
       " 471             True    True   False                   True   \n",
       " 2912            True    True   False                   True   \n",
       " \n",
       "       retain_percentile_1.0  \n",
       " 893                   False  \n",
       " 2897                   True  \n",
       " 830                   False  \n",
       " 1733                  False  \n",
       " 1183                  False  \n",
       " ...                     ...  \n",
       " 1940                  False  \n",
       " 1530                  False  \n",
       " 191                    True  \n",
       " 471                   False  \n",
       " 2912                  False  \n",
       " \n",
       " [264 rows x 24 columns],\n",
       "       student_count  awards_per_value  exp_award_value  exp_award_percentile  \\\n",
       " 2471       0.010645          0.120350         0.018950                  0.69   \n",
       " 995        0.007983          0.157549         0.031677                  0.90   \n",
       " 2203       0.016817          0.120350         0.015993                  0.55   \n",
       " 1518       0.071896          0.138585         0.010699                  0.48   \n",
       " 1592       0.011457          0.098468         0.023243                  0.80   \n",
       " ...             ...               ...              ...                   ...   \n",
       " 1902       0.026111          0.153902         0.012634                  0.38   \n",
       " 2702       0.009105          0.175055         0.009229                  0.19   \n",
       " 1189       0.061785          0.134209         0.072145                  0.99   \n",
       " 48         0.007459          0.131291         0.020451                  0.73   \n",
       " 2588       0.041159          0.117433         0.011613                  0.56   \n",
       " \n",
       "         ft_pct  fte_percentile  med_sat_value  aid_value  grad_100_value  \\\n",
       " 2471  0.961538            0.64       0.238479   0.184590           0.288   \n",
       " 995   0.997921            0.48       0.693548   0.510706           0.804   \n",
       " 2203  0.867983            0.82       0.427419   0.313423           0.414   \n",
       " 1518  0.761954            0.74       0.488479   0.116698           0.239   \n",
       " 1592  0.893971            0.65       0.194700   0.398585           0.144   \n",
       " ...        ...             ...            ...        ...             ...   \n",
       " 1902  0.783784            0.91       0.419355   0.761808           0.392   \n",
       " 2702  0.799376            0.48       0.524194   0.316887           0.267   \n",
       " 1189  0.674636            0.98       0.961982   0.922516           0.865   \n",
       " 48    0.930353            0.44       0.500000   0.446180           0.471   \n",
       " 2588  0.837838            0.52       0.442396   0.175047           0.214   \n",
       " \n",
       "       grad_100_percentile  ...  cohort_size  level_2-year  level_4-year  \\\n",
       " 2471                 0.27  ...     0.023909         False          True   \n",
       " 995                  0.93  ...     0.019411         False          True   \n",
       " 2203                 0.48  ...     0.029270         False          True   \n",
       " 1518                 0.55  ...     0.100813         False          True   \n",
       " 1592                 0.07  ...     0.019226         False          True   \n",
       " ...                   ...  ...          ...           ...           ...   \n",
       " 1902                 0.44  ...     0.054597         False          True   \n",
       " 2702                 0.23  ...     0.017685         False          True   \n",
       " 1189                 0.97  ...     0.102046         False          True   \n",
       " 48                   0.58  ...     0.023355         False          True   \n",
       " 2588                 0.48  ...     0.078999         False          True   \n",
       " \n",
       "       control_Private for-profit  control_Private not-for-profit  \\\n",
       " 2471                       False                            True   \n",
       " 995                        False                            True   \n",
       " 2203                       False                            True   \n",
       " 1518                       False                           False   \n",
       " 1592                       False                            True   \n",
       " ...                          ...                             ...   \n",
       " 1902                       False                            True   \n",
       " 2702                       False                            True   \n",
       " 1189                       False                            True   \n",
       " 48                         False                            True   \n",
       " 2588                       False                           False   \n",
       " \n",
       "       control_Public  hbcu_0  hbcu_1  retain_percentile_0.0  \\\n",
       " 2471           False   False    True                   True   \n",
       " 995            False    True   False                  False   \n",
       " 2203           False    True   False                   True   \n",
       " 1518            True    True   False                   True   \n",
       " 1592           False    True   False                   True   \n",
       " ...              ...     ...     ...                    ...   \n",
       " 1902           False    True   False                   True   \n",
       " 2702           False    True   False                   True   \n",
       " 1189           False    True   False                  False   \n",
       " 48             False    True   False                   True   \n",
       " 2588            True    True   False                   True   \n",
       " \n",
       "       retain_percentile_1.0  \n",
       " 2471                  False  \n",
       " 995                    True  \n",
       " 2203                  False  \n",
       " 1518                  False  \n",
       " 1592                  False  \n",
       " ...                     ...  \n",
       " 1902                  False  \n",
       " 2702                  False  \n",
       " 1189                   True  \n",
       " 48                    False  \n",
       " 2588                  False  \n",
       " \n",
       " [264 rows x 24 columns])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_split_data(grad_data3, 'hbcu_1', test_size=0.4, val_size=0.5, random_state=2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[249,   1],\n",
       "       [  7,   7]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redefining these values as the function didn't do this properly\n",
    "X_train = train.drop(['hbcu_1', 'hbcu_0'], axis=1).values\n",
    "y_train = train['hbcu_1'].values\n",
    "X_val = val.drop(['hbcu_1', 'hbcu_0'], axis=1).values\n",
    "y_val = val['hbcu_1'].values\n",
    "\n",
    "train_and_test(X_train, y_train, X_val, y_val, k=5, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this new model we created, we can see that the model is able to very accurately predict true negatives, and there is also an ample amount of these in the data. Out of the 256 labeled false by the model, 249 of them were correct! However, there aren't a lot of positives in the dataset to begin with (in this case this means that there aren't many historically black universities in the data set), which means that although the model got 7 correct, it labeled one false which was true, out of 8 positives. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
